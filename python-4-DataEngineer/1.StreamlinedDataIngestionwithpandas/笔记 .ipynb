{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db291a36",
   "metadata": {},
   "source": [
    "# 1.0 读取CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame of next 500 rows with labeled columns\n",
    "vt_data_next500 = pd.read_csv(\"vt_tax_data_2016.csv\", \n",
    "                       \t\t  nrows = 500,\n",
    "                       \t\t  skiprows = 500,\n",
    "                       \t\t  header = None,\n",
    "\t\t\t\t\t\t\t\tnames = list(vt_data_first500.columns)\n",
    "                       \t\t  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f814825",
   "metadata": {},
   "source": [
    "##### Set custom NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict specifying that 0s in zipcode are NA values\n",
    "null_values = {'zipcode': 0}\n",
    "\n",
    "# Load csv using na_values keyword argument\n",
    "data = pd.read_csv(\"vt_tax_data_2016.csv\", \n",
    "                   na_values = null_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_data = pd.read_csv(\"us_tax_data_2016.csv\",\n",
    "                       na_values={\"zipcode\" : 0})\n",
    "print(tax_data[tax_data.zipcode.isna()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ca23e",
   "metadata": {},
   "source": [
    "##### error_bad_lines=False, 跳过不能读取 parse的行\n",
    "##### warn_bad_lines=True，  查看跳过了多少行，显示bad行的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99595a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_data = pd.read_csv(\"us_tax_data_2016_corrupt.csv\",\n",
    "                       error_bad_lines=False,\n",
    "                       warn_bad_lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ec10c",
   "metadata": {},
   "source": [
    "# 2.1 读取表格excel sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8263f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get the second sheet by position index\n",
    "survey_data_sheet2 = pd.read_excel('fcc_survey.xlsx',\n",
    "                                   sheet_name=1)\n",
    "# Get the second sheet by name\n",
    "survey_data_2017 = pd.read_excel('fcc_survey.xlsx',\n",
    "                                 sheet_name='2017')\n",
    "print(survey_data_sheet2.equals(survey_data_2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7eb051",
   "metadata": {},
   "source": [
    "\n",
    "# 2.2 bool值读取及设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file with Yes as a True value and No as a False value\n",
    "survey_subset = pd.read_excel(\"fcc_survey_yn_data.xlsx\",\n",
    "                              dtype={\"HasDebt\": bool,\n",
    "                              \"AttendedBootCampYesNo\": bool},\n",
    "                              true_values = ['Yes'],\n",
    "                              false_values = ['No'])\n",
    "\n",
    "# View the data\n",
    "print(survey_subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5be1d",
   "metadata": {},
   "source": [
    "# 2.3 转化成时间格式 pars_dates = [] or {字典}\n",
    "\n",
    "## pd.to_datetime() to convert strings(non-standard datetime) to dates  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of columns to combine into new datetime column\n",
    "datetime_cols = {\"Part2Start\": ['Part2StartDate', 'Part2StartTime']}\n",
    "\n",
    "\n",
    "# Load file, supplying the dict to parse_dates\n",
    "survey_data = pd.read_excel(\"fcc_survey_dts.xlsx\",\n",
    "                            parse_dates = datetime_cols)\n",
    "\n",
    "\n",
    "survey_data[\"Part2EndTime\"] = pd.to_datetime(survey_data[\"Part2EndTime\"], \n",
    "                                             format=\"%m%d%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d1c87",
   "metadata": {},
   "source": [
    "# 3.0 链接数据库\n",
    "\n",
    "#### 用sqlalchemy包, 链接并创建SQL引擎 create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(\"sqlite:///data.db\")\n",
    "\n",
    "# Create a SQL query to load the entire weather table\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "  FROM weather;\n",
    "\"\"\"\n",
    "\n",
    "# Load weather with the SQL query\n",
    "weather = pd.read_sql(query, engine)\n",
    "\n",
    "# View the first few rows of data\n",
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0dea8a",
   "metadata": {},
   "source": [
    "# 4.0 JSON文件的接入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b7c26",
   "metadata": {},
   "source": [
    "## 4.1 pd.read_json( '文件名.json' , orient = 'split')\n",
    "\n",
    "第一参数就是json文件路径或者json格式的字符串。\n",
    "\n",
    "第二参数orient是表明预期的json字符串格式, orient = 包括“split\", 'index', 'records', 'columns', 'values' 详细查看 http://www.manongjc.com/article/50826.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load the JSON with orient specified\n",
    "    df = pd.read_json(\"dhs_report_reformatted.json\",\n",
    "                      orient = 'split')\n",
    "    \n",
    "    # Plot total population in shelters over time\n",
    "    df[\"date_of_census\"] = pd.to_datetime(df[\"date_of_census\"])\n",
    "    df.plot(x=\"date_of_census\", \n",
    "            y=\"total_individuals_in_shelter\")\n",
    "    plt.show()\n",
    "    \n",
    "except ValueError:\n",
    "    print(\"pandas could not parse the JSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5e4bb",
   "metadata": {},
   "source": [
    "## 4.2 APIs \n",
    "接入其它程序，在不知道数据库details时获取数据\n",
    "\n",
    "#### requests.get( url_string, params, headers)\n",
    "params 要到API-document里查看\n",
    "headers 如果有保密措施”authentication“，需要取得授权\n",
    "#### data = response.json() 返回.json 文档，字典格式\n",
    "#### pd.DataFrame(data) 用dataframe打开json文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975c8d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b5f25a97dec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create dictionary that passes Authorization and key string, headers 和 params都是字典格式的参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Authorization'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Bearer {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Get data about NYC cafes from the Yelp API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api_key' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "api_url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "\n",
    "# Create dictionary to query API for cafes in NYC\n",
    "parameters = {'term' :'cafe',\n",
    "          \t  'location': 'NYC'}\n",
    "\n",
    "# Create dictionary that passes Authorization and key string, headers 和 params都是字典格式的参数\n",
    "headers = {'Authorization': \"Bearer {}\".format(api_key)}\n",
    "\n",
    "# Get data about NYC cafes from the Yelp API\n",
    "response = requests.get(api_url, \n",
    "                headers=headers, \n",
    "                params=params)\n",
    "\n",
    "# Extract JSON data from the response， 返回的是字典格式，所以不能用pd.read_json(), read_json()只能读取string格式。\n",
    "data = response.json()\n",
    "\n",
    "# Load data to a data frame, 选取‘businesses'这个key的所有values\n",
    "cafes = pd.DataFrame(data['businesses'])\n",
    " \n",
    "# View the data's dtypes\n",
    "print(cafes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13bf3b",
   "metadata": {},
   "source": [
    " ## 4.3 处理Nested json\n",
    " A feature of JSON data is that it can be nested: an attribute's value can consist of attribute-value pairs. （详见本课chapter4 .json图）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e923328",
   "metadata": {},
   "source": [
    "### Flatten nested JSONs\n",
    "##### json_normalize()   \n",
    "##### pandas.json_normalize(data:Union[Dict, List[Dict]], record_path:Union[str, List, NoneType] = None, meta:Union[str, List[Union[str, List[str]]], NoneType] = None, meta_prefix:Union[str, NoneType] = None, record_prefix:Union[str, NoneType] = None, errors:Union[str, NoneType] = 'raise', sep:str = '.', max_level:Union[int, NoneType] = None) → 'DataFrame'\n",
    "\n",
    "data：dict 或 list of dicts\n",
    "未序列化的JSON對象。\n",
    "\n",
    "record_path：str 或 list of str, 默認為 None\n",
    "每個對象到記錄列表的路徑。如果未通過，則數據將假定為記錄數組。\n",
    "\n",
    "meta：list of paths (str 或 list of str), 默認為 None\n",
    "用作結果表中每個記錄的元數據的字段。\n",
    "\n",
    "meta_prefix：str, 默認為 None\n",
    "如果為True，則前綴記錄帶有點(？)路徑，例如foo.bar.field，如果meta為[‘foo’，‘bar’]。\n",
    "\n",
    "record_prefix：str, 默認為 None\n",
    "如果為True，則前綴記錄帶有點(？)路徑，例如foo.bar.field，如果記錄的路徑是[‘foo’，‘bar’]。\n",
    "\n",
    "errors：{‘raise’, ‘ignore’}, 默認為 ‘raise’\n",
    "配置錯誤處理。\n",
    "\n",
    "‘ignore’：如果meta中列出的鍵並非總是存在，將忽略KeyError。\n",
    "\n",
    "‘raise’：如果meta中列出的鍵並非總是存在，將引發KeyError。\n",
    "\n",
    "sep：str, 默認為 ‘.’\n",
    "嵌套記錄將生成用sep分隔的名稱。例如，對於sep =’。’，{‘foo’：{‘bar’：0}}-> foo.bar。\n",
    "\n",
    "max_level：int, 默認為 None\n",
    "要進行標準化的最大級別數(詞典的深度)。如果為None，則將所有級別標準化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json_normalize()\n",
    "from pandas.io.json import json_normalize    \n",
    "\n",
    "# Isolate the JSON data from the API response\n",
    "data =  response.json()\n",
    "\n",
    "# Flatten business data into a data frame, replace separator\n",
    "cafes = json_normalize(data[\"businesses\"],\n",
    "             sep= '_')\n",
    "\n",
    "# View data\n",
    "print(cafes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fe9de",
   "metadata": {},
   "source": [
    "### Handle deeply nested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load other business attributes and set meta prefix\n",
    "flat_cafes = json_normalize(data[\"businesses\"],\n",
    "                            sep=\"_\",\n",
    "                    \t\trecord_path=\"categories\",\n",
    "                    \t\tmeta =['name', \n",
    "                                  'alias',  \n",
    "                                  'rating',\n",
    "                          \t\t  ['coordinates', 'latitude'], \n",
    "                          \t\t  ['coordinates', 'longitude']],\n",
    "                    \t\tmeta_prefix = \"biz_\")                    #\n",
    "\n",
    "\n",
    "# View the data\n",
    "print(flat_cafes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68a79e",
   "metadata": {},
   "source": [
    "## 4.4 Combining multiple datasets\n",
    "\n",
    "### 4.4.1 append() 竖向🔗tables\n",
    "\n",
    "#### df1.append(df2, ignore_index = [ True #忽视pd.DataFrame的默认行index, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf339e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an offset parameter to get cafes 51-100\n",
    "params = {\"term\": \"cafe\", \n",
    "          \"location\": \"NYC\",\n",
    "          \"sort_by\": \"rating\", \n",
    "          \"limit\": 50,\n",
    "          'offset': 50}\n",
    "\n",
    "result = requests.get(api_url, headers=headers, params=params)\n",
    "next_50_cafes = json_normalize(result.json()[\"businesses\"])\n",
    "\n",
    "# Append the results, setting ignore_index to renumber rows\n",
    "cafes = top_50_cafes.append(next_50_cafes, ignore_index = True)\n",
    "\n",
    "# Print shape of cafes\n",
    "print(cafes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a5272",
   "metadata": {},
   "source": [
    "### 4.4.2 merge() 横向🔗tables， 类似SQL 的join\n",
    "\n",
    "#### df1.merge(df2, left_on = 'df1.fk', right_on = 'df2.pk' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3637ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge crosswalk into cafes on their zip code fields\n",
    "cafes_with_pumas = cafes.merge(crosswalk, left_on = 'location_zip_code', right_on='zipcode')\n",
    "\n",
    "# Merge pop_data into cafes_with_pumas on puma field\n",
    "cafes_with_pop =  cafes_with_pumas.merge(pop_data, left_on = 'puma', right_on = 'puma')\n",
    "\n",
    "# View the data\n",
    "print(cafes_with_pop.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
